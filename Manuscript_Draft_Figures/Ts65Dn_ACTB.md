#Adaptation of the Arizona Cognitive Task Battery for use with the Ts65Dn Mouse Model of Down Syndrome

###Michael R. Hunsaker, Ph.D., Genevieve K. Smith, Raymond P. Kesner, Ph.D.

####University of Utah

#Background & Introduction

With the increasing sophistication of the genetic techniques used to develop mouse models of genetic disorders, it is imperative that the techniques used to elucidate the behavioral phenotype of these models evolve just as rapidly. Although there is a movement toward adopting standardized behavioral phenotyping protocols, to a large degree neuroscientists evaluating mouse models of genetic disorders still lack sensitive behavioral assays needed to evaluate the core cognitive deficits present in genetic disorders. At present, mouse models, particularly those developed to study neurodevelopmental or other genetic disorders, demonstrate inconsistent phenotypes or entirely lack behavioral phenotypes when tested using the most common behavioral tasks: including the water maze, Barnes maze, active / passive avoidance, rotarod, or fear conditioning. Furthermore, it has been shown that even extremely subtle differences between individual laboratory protocols for these common tasks changes observed phenotypes (*e.g.*, differences in care taken while fixing a rough surface to a rotarod has been shown to dissociate performance across collaborating laboratories studying the same mouse strain).

Additionally, mouse models often demonstrate phenotypes that are not specifically associated with any genetic disorder in particular, but are more aptly described as shared clinical phenotypes that similarly present across a wide array of disorders (*e.g.*, gross learning and memory deficits, anxiety, depression). The interpretation of such inconclusive findings is often that the mouse model fails to recapitulate the phenotypes observed in patients. Unfortunately, these types of findings are analogous to inconsistent findings in clinical populations when standardized neuropsychological tests are administered -- many different populations show very similar deficits despite nonoverlapping genetic or developmental disorders. Such inconsistencies often renders behavioral research into developmental or psychiatric disorders frustrating and such anomalous findings mask the differences that do exist. I propose that inconsistent behavioral results observed in clinical populations as well as mouse models do not infer the lack of cognitive impairments, but rather these "null" data reflect the often startling insensitivity of the behavioral tasks commonly employed.

In situations where, based on standardized behavioral tasks, mouse models do not appear to specifically model clinical phenotypes observed in patient populations, one strategy is to evaluate intermediate- or endophenotypes associated specifically with the genetic mutation and subserved by neuroanatomical structures disrupted by the mutation. A similar process applies to studies of human clinical populations when standardized tests fail to uncover phenotypes that are present, but only manifest at a subclinical level.

Endophenotypes are collections of quantitative traits hypothesized to represent risk for genetic disorders at more biologically (and empirically) tractable levels than the full clinical phenotype; which often contains little more than profound deficits shared across various genetic disorders. A behavioral endophenotyping approach facilitates the identification of behavioral deficits that are clearly associated with both the specific genetic mutation and the pathological features observed in the clinical populations being modeled -- and more importantly with the pathological/clinical features unique to the population being modeled. When designed to evaluate such disease-specific hypotheses, behavioral endophenotypes model quantitative patterns of behavioral deficits that scale with the size and / or severity of the genetic mutation .

The behavioral endophenotyping process deviates from the currently accepted method for determining behavioral phenotypes. The present method is to determine phenotypes in clinical populations and mouse models-that of using behavioral tasks that were designed without prior consideration of the pathology and anecdotal features present in the population. Far too often an approach such as this is not sufficiently sensitive to characterize gene-brain-behavior interactions that underlie disease pathogenesis. In contrast with the currently utilized approach, behavioral endophenotyping emphasizes the use of behavioral paradigms that were developed to specifically evaluate a priori hypotheses concerning the alterations to nominal gene-brain-behavior interactions identified or proposed to exist in a given population using carefully selected tasks to identify unique phenotypes within each model; and thus are more capable of characterizing the neurocognitive consequences of the specific gene mutations underlying the genetic disorder.

##Neuropsychological Aspects of Down Syndrome

**Need a review of the state of what is known from studies of subjects with Down Syndrome**

###Phenotyping Approach

Any discussion concerning the behavioral phenotyping of mouse models of genetic disorders must necessarily begin with a description of what a behavioral phenotype is and what assumptions underly tasks used to evaluate them. In short, behavioral phenotyping quantifies performance of mutant mice across behavioral experiments; and the behavioral performance is related to the clinical population to identify parallels that may exist. The analogy between the phenotype of human genetic disorder and the behavioral phenotype of the mouse model can be expressed as a combination of three factors: face validity, construct or content) validity, and predictive validity.

**Face validity** is the surface similarity between the behavior of the mouse model and the patient on analogous tasks (i.e., does the performance of the mouse and human resemble each other at face value). In other words, if a mouse has to perform a similar response during a task as the patient makes during performance of a similar task, the task shows face validity. Similarly, if the mouse and human behavioral tasks can be intuitively interpreted as being similar, the task shows face validity.

**Construct (or content) validity**, so far as the development of behavioral experiments is concerned, refers to the similarity between the behavioral or cognitive domains being tested by a given task in the mouse model and human patient. This means that for tests to show construct validity, the tasks must be designed to directly model specific aspects of the genetic disorder and additionally that performance be subserved by similar neural substrates and/or cognitive process across species. More specifi- cally, the tasks need to be developed to explicitly model the human disorder, not solely rely on creative post hoc interpretations of behavioral performance on general behavioral tasks. One necessity of construct validity is that a basic understanding of the disorder being modeled is required, such that the research is into translating a behavioral phenotype across species, not providing the primary elucidation of any phenotype at all in a model.

**Predictive validity** refers to the utility of a mouse model as a proxy for the patient in studies of disease progression or therapeutic intervention—this can refer to either the endpoints of a behavioral study or the physiology of the model. Although predictive validity is commonly thought of as a characteristic of phenotyping approaches, it is more accurate to state that predictive validity is the quantified endpoint of an adequately
designed behavioral phenotyping experiment—that is, to define some behavior or set of behaviors that serve as valid outcome measures for later studies. In other words, predictive validity is only present when behavioral performance of the model during a given experiment proves useful for inferring or correlating dosage of a given mutation, disease progression, or treatment outcomes in not only the model, but also the clinical population.

---

Commonly, the selection of behavioral tasks to evaluate a behavioral phenotype emphasizes either a high-throughput battery tasks to determine gross deficits for cognitive function or a limited selection of tasks that roughly assay cognitive processing. There are definite advantages to this approach as it provides a rich array of information from commonly implemented, easily interpreted tasks, but this approach does not explicitly model the behavioral phenotypes of the human disorder being modeled. When a behavioral screening approach becomes essential is for the primary screen for phenotypes in novel mouse disease models. For example, in cases where the mouse model has not been evaluated for gross cognitive function, this process is analogous to initial neuropsychological screens given in the clinic prior to more in depth neurocognitive testing.

##Neurocognitive Testing: Arizona Cognitive Task Battery

**Need a review of the state of the ACTB at present**


###Endophenotyping Approach

There is one clear difference between identifying a behavioral phenotype and identifying a behavioral endophenotype. This difference is that to evaluate a behavioral phenotype, the researcher need only look for a difference in behavior among a homogeneous group of mutant mice relative to littermate or strain-matched control group. This main effect is then used as evidence for some kind of behavioral impairment. This process is akin to using the same battery of standardized neuropsychological tests to evaluate the behavioral consequences of number of different genetic disorders and then trying to make inferences about what are the specific profiles of strengths and weaknesses unique to each disorder. In contrast, to evaluate a behavioral endophenotype in the same mice, there is a requirement that any behavioral phenotype predictably scale across some measure: Usually such factors include age, genetic dosage in situations of polymorphic mutations or chromosomal aneuploidy, or some other experimentally controlled factor that is altered parametrically (*e.g.*, stress, environmental toxicant exposure, etc.). This process is similar to how experimental psychology or cognitive neuroscience approaches to studying the behavior of populations carrying genetic mutations. That is, an approach that emphasizes using hypothesis driven tests that have been designed to evaluate hypothesized effects within the population being studied, irrespective to performance of other populations.

The importance of finding a behavioral endophenotype is that if there is a predictable relationship among cognitive performance and gene expression, it can be assumed that the genetic mutation alters behavioral output; and subsequently, some sort of relationship between the two exists. Such a finding not only provides a wealth of information that helps the researcher design future experiments, but also data that are useful as outcome measures for studies of intervention that alter or even potentially mitigate some negative impact of the mutation. If there is a more complex relationship wherein age appears to modulate the relationship between the mutation and behavioral output, then those data serve not only as outcome measures, but if well enough understood, could be potentially useful to define risk prodromes to predict future symptomatology or disease progression.

One reason we propose underlying the lack of direct applicability of mouse model research for drug discovery is the unfortunate focus on gross phenotypes that may be either at best secondary to the mutation or result from mouse-unique factors that do not scale evolutionarily. Stated more colloquially, it is much easier to cure disease in mice than to translate the murine research into actually curing human disease. The same general paradigm is prevalent in research into sequelae resultant to neurodevelopmental/neurodegenerative genetic diseases. As a scientific community, we have been able to identify and provide *cures* for a wide range mouse models of genetic disorders (*i.e.*, Down Syndrome), but to date these cures have not proven particularly useful for ameliorating symptoms of human genetic disease: often failing or providing only marginal effects during early phase clinical trials. Elucidating behavioral or neurocognitive endophenotypes using tasks designed to test specific disease-related hypotheses is one proposed solution to mitigate this lack of efficacy in the mouse model.

For these, as well as many other reasons, research into schizophrenia has forced the field to changed their general approach, and emphasized an endophenotyping approach in the study of prodromal states associated with schizophrenia onset and symptom progression (*e.g.*, focusing research on longitudinal analyses of 22q11.2 deletion populations rather than on *de novo* schizophrenia cases of unknown or poorly understood genetic origin). By focusing on factors that scale with disease or symptom severity, researchers have been able to understand far more about schizophrenia and what may underlie symptom progression than they would otherwise have been able using a standardized, neuropsychological phenotyping approach.

In this study we evaluate propose a clear strategy to efficiently and comprehensively characterize neurobehavioral deficits in the Ts65Dn mouse model of Down Syndrome. This approach uses neurocognitive theory to design and select behavioral tasks that test specific hypotheses concerning the genetic disorder being studied-specifically those proposed as part of the Arizona Cognitive Task Battery (ACTB) used to study human populations with Down Syndrome. This approach extends the utility of mouse models by integrating the expertise of clinical neurology and cognitive neuroscience into the mouse behavioral laboratory. Further, by directly emphasizing the reciprocal translation of research between human disease states and the associated mouse models, we demonstrate is is possible for both groups to mutually inform each other’s research to more efficiently generate hypotheses and elucidate treatment strategies.

#Materials and Methods

#Animals

In this study, 10 trisomic male Ts65Dn/DnJ mice and 10 age-matched wild type littermates were obtained from Jackson Laboratories (Bar Harbor, ME) and tested at 5-7 months of age, at an average weight of 33 +/- 3.8g (standard error). Animals were kept on a 12-h light/dark cycle, in a temperature and humidity controlled environment with *ad libitum* access to food and water. All behavioral tests were conducted during the light portion of the cycle (06:00-18:00). Mice were housed in same-genotype groups of 2-3 per cage. Animal care and experimental testing procedures conformed to NIH, IACUC, and AALAC standards and protocols.

As detailed by Jackson Laboratory, the segmentally trisomic Ts<sup>(1716)</sup>65Dn mice have three copies of genes at the distal 15% of mouse chromosome 16 and span the region orthologous to genes on human chromosome 21. These extra genes, centromere, and about 5% of proximal mouse chromosome 17 are contained in the small extra chromosome derived from a reciprocal translocation. About 15% of the distal end of mouse chromosome 16 is fused to the centromeric end of chromosome 17 to form the small translocation chromosome. The translocation breaks mouse chromosome 16 just proximal to the amyloid precursor protein (*App*) gene and contains the chromosome 21-homologous genes from *App* to the telomere. The Ts65Dn/DnJ stock, commercially available from Jackson Laboratory, is homozygous for the wild type allele for retinal degeneration. The stock is maintained by repeated backcrossing of Ts65Dn females to B6EiC3H F1 hybrid males derived from a new congenic strain of C3H mice. This new congenic strain (C3Sn.BLiA-Pde6b+) lacks the blindness causing recessive mutant allele.

#Behavioral Tasks

The week prior to testing, all animals were handled in 15 min daily sessions and given an opportunity to habituate to the clear or red apparatus for at least 15 min and acclimate to sucrose pellet rewards.

##Spatiotemporal Attributes

###Spatial

####Cheeseboard

Method:
Each mouse was habituated to the cheeseboard for 30 min the day prior to experimentation with food pellets distributed in each hole. At the beginning of each trial, a sucrose reward pellet was placed in one of the holes of the cheeseboard (in the midpoint of  the North-East, North-West, South-East or South-West quadrant). A mouse was then released at one of the cardinal points (*e.g.,* North, South, East, or West) as latency in seconds and distance in cm covered to reach the reward was recorded. Each day, the mouse received a trial from each of the four cardinal directions (order randomized between mice and between days within mice). There were 5 minutes separating each trial for each mouse. After the fourth day of training, the mice were given a probe trial wherein there was no reward. The search patterns of the mice were evaluated.

![Cheeseboard](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Cheeseboard.png?raw=TRUE)

*Figure Caption: Layout of the Cheeseboard apparatus in the experimental space. The cheeseboard measured 1 m in diameter and was elevated 1 m from the floor.*

---

####Metric / Coordinate Processing

Method:
Each mouse had previously been habituated to the clear and red experimental boxes. For the metric/coordinate test, two objects were placed in the box separated by 25 cm (from inner edges) and mice were allowed to explore the objects for 15 minutes. After a 5 min interval during which the mice were covered by a heavy cup, the objects were moved closer together to an 8 cm separation and the mouse was allowed to explore for 5 min. This procedure was carried out in the clear box that allowed the mouse to see the extra-maze, distal cues as well as in the red box that blocked the ability of the mouse to see these cues. Exploration during the last 5 min of habituation and during the 5 min test session were converted into a ratio value ranging [-1,1] to control for overall exploration. As such, a ratio value approaching -1 is interpreted as the mouse showing continued habituation and thus not noticing the change. A ratio value approaching 1 suggest the mouse dramatically explored the change.

![Coordinate](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Clear_Metric.png?raw=TRUE)

*Figure Caption: Layout of the Metric or Coordinate task in the experimental space. With the clear box, the mice were able to use distal cues to guide behavioral decisions*

---

![Coordinate](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Red_Metric.png?raw=TRUE)

*Figure Caption: Layout of the Metric or Coordinate task in the experimental space. With the red box, the mice did not have access to distal cues to guide behavioral decisions*

---

####Topological / Categorical Processing

Method:
Each mouse had previously been habituated to the clear and red experimental boxes. For the topological/categorical test, four objects were placed in a square in the box separated by 25 cm (from inner edges) and mice were allowed to explore the objects for 15 minutes. After a 5 min interval during which the mice were covered by a heavy cup, the front two objects were transposed, and the mouse was allowed to explore for 5 min. This procedure was carried out in the clear box that allowed the mouse to see the extra-maze, distal cues as well as in the red box that blocked the ability of the mouse to see these cues. Exploration during the last 5 min of habituation and during the 5 min test session were converted into a ratio value ranging [-1,1] to control for overall exploration. As such, a ratio value approaching -1 is interpreted as the mouse showing continued habituation and thus not noticing the change. A ratio value approaching 1 suggest the mouse dramatically explored the change.

![Categorical](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Clear_Topological.png?raw=TRUE)

*Figure Caption: Layout of the Topological or Categorical task in the experimental space. With the clear box, the mice were able to use distal cues to guide behavioral decisions*

---

![Categorical](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Red_Topological.png?raw=TRUE)

*Figure Caption: Layout of the Topological or Categorical task in the experimental space. With the red box, the mice did not have access to distal cues to guide behavioral decisions*

---

####Location Recognition

Method:
Each mouse had previously been habituated to the clear and red experimental boxes. For the location recognition test, two objects were placed in the box separated by 25 cm (from inner edges) and mice were allowed to explore the objects for 15 minutes. After a 5 min interval during which the mice were covered by a heavy cup, one of the objects was moved at a diagonal to a new location (still 25 cm separation from the other object), and the mouse was allowed to explore for 5 min. This procedure was carried out in the clear box that allowed the mouse to see the extra-maze, distal cues as well as in the red box that blocked the ability of the mouse to see these cues. Exploration during the last 5 min of habituation and during the 5 min test session were converted into a ratio value ranging [-1,1] to control for overall exploration. As such, a ratio value approaching -1 is interpreted as the mouse showing continued habituation and thus not noticing the change. A ratio value approaching 1 suggest the mouse dramatically explored the change.

![Location Recognition](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Clear_LocationRecognition.png?raw=TRUE)

*Figure Caption: Layout of the Location Recognition task in the experimental space. With the clear box, the mice were able to use distal cues to guide behavioral decisions*

---

![Location Recognition](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Red_LocationRecognition.png?raw=TRUE)

*Figure Caption: Layout of the Location Recognition task in the experimental space. With the red box, the mice did not have access to distal cues to guide behavioral decisions*

---

###Temporal Attribute

####Temporal Ordering for Visual Objects

Method:
During session 1, two identical copies of a first object (object 1) were placed at the ends of the box 2.5 cm from the end walls and centered between the long walls. The mouse was placed in the center of the box facing away from both objects. The mouse was given 5 min to freely explore the objects. After 5 min, the mouse was removed to a small holding cup for 5 min. During this time, the first objects were replaced with two duplicates of a second object (Object 2). For Session 2, the mouse was again placed in the apparatus and allowed to explore. After 5 min, the mouse was removed to the holding cup for 5 min and the objects were replaced with two duplicates of a third object (Object 3). For Session 3, the mouse was given 5 min to explore. After 5 min, the mouse was removed into a small cup for 5 min and an unused copy of the first and an unused copy of the third object were placed into the box. The mouse was again placed into the box and allowed to explore the two objects (*i.e.*, Objects 1 and 3) during a 5 min test session. This procedure was carried out in the clear box that allowed the mouse to see the extra-maze, distal cues as well as in the red box that blocked the ability of the mouse to see these cues. Exploration of each object during the test session were converted into a ratio value ranging [-1,1] to control for overall exploration. As such, a ratio value approaching -1 is interpreted as the mouse showing an absolute preference for the third over the first object. A ratio value approaching 1 suggest the mouse strongly explored the first over the third object.


![Temporal Ordering](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Clear_TemporalOrdering.png?raw=TRUE)

*Figure Caption: Layout of the Temporal Ordering for Visual Objects task in the experimental space. With the clear box, the mice were able to use distal cues to guide behavioral decisions*

---

![Temporal Ordering](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Red_TemporalOrdering.png?raw=TRUE)

*Figure Caption: Layout of the Temporal ordering for Visual Objects task in the experimental space. With the red box, the mice did not have access to distal cues to guide behavioral decisions*

---

####Temporal Order Control: Novelty Detection for Visual Objects

Method:
In addition to reflecting impaired temporal ordering, increased exploration of the first object over the third could also be interpreted as being due to difficulty in remembering the first object prior to the test session. To minimize and con- trol for such general memory deficits, a novelty detection of visual objects task was performed. Briefly, on a different day mice received three sessions during which they were allowed to explore three novel sets of objects (Objects 4, 5, 6) similarly to the temporal ordering tasks. During the test session, the first object and a novel fourth object (Object 7) were presented and the mice were allowed 5 min to explore.  This procedure was carried out in the clear box that allowed the mouse to see the extra-maze, distal cues as well as in the red box that blocked the ability of the mouse to see these cues. Exploration of each object during the test session were converted into a ratio value ranging [-1,1] to control for overall exploration. As such, a ratio value approaching -1 is interpreted as the mouse showing an absolute preference for the familiar over the novel object. A ratio value approaching 1 suggest the mouse strongly explored the novel over the familiar object.

![Novelty Detection](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Clear_NoveltyDetection.png?raw=TRUE)

*Figure Caption: Layout of the Novelty Detection for Visual Objects task in the experimental space. With the clear box, the mice were able to use distal cues to guide behavioral decisions*

---

![Novelty Detection](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Red_NoveltyDetection.png?raw=TRUE)

*Figure Caption: Layout of theNovelty Detection for Visual Objects task in the experimental space. With the red box, the mice did not have access to distal cues to guide behavioral decisions*

##Sensory/Perceptual Attributes

####Feature Ambiguity

Method:
Each mouse had previously been habituated to the clear and red experimental boxes. For the configural recognition condition, mice were placed for 15 min in the red box containing two compound objects, AB and CD, separated by 15 cm. Following a 5 min delay under a heavy cup, the mouse underwent a 5-min Test Phase in which one object from the Study Phase remained the same (AB) and the other compound object is created from one component of each of the previous familiar objects, (*e.g.*, AD). That is, the “novel” object (AD) is composed of the same elements, but rearranged into a novel configuration. Therefore, the object is “novel” by virtue of its configuration, not by its elements, each of which is present in one of the compound stimuli in the habituation phase.Exploration of each compound object was scored as a single unit. Exploration during the last 5 min of habituation and during the 5 min test session were converted into a ratio value ranging [-1,1] to control for overall exploration. As such, a ratio value approaching -1 is interpreted as the mouse showing continued habituation and thus not noticing the change. A ratio value approaching 1 suggest the mouse dramatically explored the change.

![Ambiguity](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Clear_Ambiguity.png?raw=TRUE)

*Figure Caption: Layout of the Configural Ambiguity task in the experimental space. With the clear box, the mice were able to use distal cues to guide behavioral decisions*

---

![Ambiguity](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Red_Ambiguity.png?raw=TRUE)

*Figure Caption: Layout of the Configural Ambiguity task in the experimental space. With the red box, the mice did not have access to distal cues to guide behavioral decisions*

---

####Feature Ambiguity Control: Novelty Detection for Configural Objects

Method:
Each mouse had previously been habituated to the clear and red experimental boxes. For the configural recognition condition, mice were placed for 15 min in the red box containing two compound objects, AB and CD, separated by 15 cm. Following a 5 min delay under a heavy cup, the mouse underwent a 5-min  control task during which CD was replaced by two never before seen objects (EF) was also performed. This procedure was carried out in the clear box that allowed the mouse to see the extra-maze, distal cues as well as in the red box that blocked the ability of the mouse to see these cues. Exploration during the last 5 min of habituation and during the 5 min test session were converted into a ratio value ranging [-1,1] to control for overall exploration. As such, a ratio value approaching -1 is interpreted as the mouse showing continued habituation and thus not noticing the change. A ratio value approaching 1 suggest the mouse dramatically explored the change.

![Ambiguity Control](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Clear_Ambiguity_Control.png?raw=TRUE)

*Figure Caption: Layout of the Configural Ambiguity Control task in the experimental space. With the clear box, the mice were able to use distal cues to guide behavioral decisions*

---

![Ambiguity Control](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Red_Ambiguity_Control.png?raw=TRUE)

*Figure Caption: Layout of the Configural Ambiguity Control task in the experimental space. With the red box, the mice did not have access to distal cues to guide behavioral decisions*

---

####Object Recognition at 1 hour and 24 hour delays

Method:
Each mouse had previously been habituated to the clear and red experimental boxes. For the object recognition test, two objects were placed in the box separated by 25 cm (from inner edges) and mice were allowed to explore the objects for 15 minutes. After a 5 min interval during which the mice were covered by a heavy cup, one of the objects was replaced by a novel object that had never before been experienced byt he mouse, and the mouse was allowed to explore for 5 min. This procedure was carried out in the clear box that allowed the mouse to see the extra-maze, distal cues as well as in the red box that blocked the ability of the mouse to see these cues. This procedure was carried out in each box separately for delays of 1 and 24 hours. Exploration during the last 5 min of habituation and during the 5 min test session were converted into a ratio value ranging [-1,1] to control for overall exploration. As such, a ratio value approaching -1 is interpreted as the mouse showing continued habituation and thus not noticing the change. a ratio value approaching 1 suggest the mouse dramatically explored the change.


![Object Recognition](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Clear_ObjectRecognition.png?raw=TRUE)

*Figure Caption: Layout of the Object Recognition task in the experimental space. With the clear box, the mice were able to use distal cues to guide behavioral decisions*

---

![Object Recognition](https://raw.github.com/mrhunsaker/Ts65DnPilots/master/Manuscript_Draft_Figures/Diagrams/Red_ObjectRecognition.png?raw=TRUE)

*Figure Caption: Layout of the Object Recognition task in the experimental space. With the red box, the mice did not have access to distal cues to guide behavioral decisions*


##Executive Function

####Spontaneous Alternation

Method:
Mice were placed in the stem of a Y maze and allowed to explore. Whenever the mouse entered one of the arms of the Y maze with all four limbs their response was recorded. The number of times the mouse alternated (*i.e.,* did not repeat the previous turn), it was recorded as an alternation.

####Response Learning

Method:
Mice were placed in the stem of a Plus maze with one of the arms blocked off (forming a T maze). Mice were given five trials to determine if there was any preference for one direction over the other. As no such preference was observed, mice were randomly assigned the rule to turn right or turn left. Mice received 20 trials per day for 4 days. Entry into an arm with all four limbs was recorded as a choice and mice were not allowed to self correct when they made mistakes.

####Reversal Learning

Method:
The day after mice finished training on response learning, they received 80 trials of reversal training. This means that the turn the mice had just learned to make for reward was now incorrect, rather the mice had to make the opposite turn to receive reward. Number of previously correct choices made were recorded as errors and error type was evaluated as perseverative or regressive based on the work of Aggleton and Ragozzino.

##Motor Function

####Capellini Handling

Method:
Mice were habituated over a weekend to dried capellini pasts in their cages. Each mouse was placed in a 250 mL beaker and given a 5 cm piece of dried capellini. Their behaviors while eating were recorded for an offline analysis of their motor behaviors. Their latency to finish each piece of pasta was recorded, as were abnormal behaviors including the mouse having its paws together while eating, losing contact with the pasta with one or both paws, and using the mouth to pull the pasta rather than using the digits to feed the pasta into the mouth.

####Parallel Rung Walking

Method:
Mice were placed in a box measuring 15 cm squared with 1.5 mm diameter parallel rungs making up the floor. The mice were allowed to freely explore the box for 5 minutes. The number of times a paw slipped through the parallel rod floor beyond the wrist or ankle, a "foot slip" error was recorded. The total number of steps were also recorded to use as a normalizing factor.

##Adaptive Function

####Nesting Behaviors

Method:
Sawdust was used to fill a 10 cm long piece of 2" (~5 cm) diameter PVC pipe that was capped at one end. This pipe was placed in a cage with each mouse and the latency to contact the sawdust in the pipe, the latency to start digging in the sawdust, and the latency to finalize the nest were recorded.

####Neophagia

Method:
Mice were given three neophagia tests. The first was in their homecage. Each mouse was provided a food they had never encountered (Cheerios cereal) and the latcny to take the first bite was recorded. The second test was each mouse was placed on a large platter in a bright area int he testing room and the latency to take a bite from a reward pellet (familiar food) was recorded. The final test consisted of each mouse being placed in a novel white box and fed a Cheerio that had been stored with thyme overnight, resulting in a novel food. Again, latency to take the first bite was recorded.

#Statistical Analysis

##Tests for equal variance and heteroscedasticity.

Prior to statistical analyses, the data were tested for normalcy (Shapiro–Wilk test) and homoscedacity (Browne–Forsythe test). Once deemed appropriate, further statistical analyses were performed using parametric analyses of variance. All results were considered significant at an alpha < 0.05 and Power (1-beta) < 0.8, and analyses were performed to determine observed power and effect size of all main effects. Statistical analyses were performed in R 3.0.1. language and environment and statistical power was calculated using both R and the statistical program G*Power 3. All reported p values were adjusted for False Discovery Rate using a custom script written in R 3.0.1.

##Principal Component Analyses

PCA were run by applying the functions in FactoMineR in R 3.0.1.

#Results

##Spatiotemporal Processing

###Spatial

####Cheeseboard

![Cheeseboard Latency](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/Cheeseboard_TRACK.png?raw=TRUE)

*Figure Caption: Top. 2N wildtype mouse performance on cheeseboard. Bottom. Ts65Dn mouse performance on cheeseboard.*

	"Cheeseboard_RawLatency"
	Error: Within
	                                    Df Sum Sq Mean Sq F value Pr(	F)
	cheeseboard$GROUPS                   1  42228   42228 185.645 <2e-16 ***
	cheeseboard$DAYS                     1 151010  151010 663.876 <2e-16 ***
	cheeseboard$GROUPS:cheeseboard$DAYS  1     76      76   0.333  0.566
	Residuals                           76  17287     227
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	"Cheeseboard_ScaledLatency"
	Error: Within
	                                    Df Sum Sq Mean Sq F value   Pr(	F)
	cheeseboard$GROUPS                   1   4424    4424   48.44 1.05e-09 ***
	cheeseboard$DAYS                     1  70015   70015  766.64  < 2e-16 ***
	cheeseboard$GROUPS:cheeseboard$DAYS  1   1346    1346   14.74 0.000253 ***
	Residuals                           76   6941      91
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

![Cheeseboard Latency](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/Cheeseboard_Latency.pdf?raw=TRUE)

*Figure Caption: Top. Raw latency (s) to obtain reward. Bottom. Percent latency to obtain reward each day scaled by latency on Day 1.*

	"Cheeseboard_RawDistance"
	Error: Within
	                                    Df  Sum Sq Mean Sq F value   Pr(	F)
	cheeseboard$GROUPS                   1 1675916 1675916  88.406 2.27e-14 ***
	cheeseboard$DAYS                     1 2830638 2830638 149.318  < 2e-16 ***
	cheeseboard$GROUPS:cheeseboard$DAYS  1    4893    4893   0.258    0.613
	Residuals                           76 1440741   18957
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	"Cheeseboard_ScaledDistance"
	Error: Within
	                                    Df Sum Sq Mean Sq F value   Pr(	F)
	cheeseboard$GROUPS                   1   5680    5680  25.194 3.32e-06 ***
	cheeseboard$DAYS                     1  30934   30934 137.217  < 2e-16 ***
	cheeseboard$GROUPS:cheeseboard$DAYS  1    876     876   3.887   0.0523 .
	Residuals                           76  17133     225
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

![Cheeseboard Distance](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/Cheeseboard_Distance.pdf?raw=TRUE)

*Figure Caption: Top. Raw distance (cm) to obtain reward. Bottom. Percent distance to obtain reward each day scaled by latency on Day 1.*

**Note: I do have the probe trial data, it is not very convincing as control mice almost immediately realize we moved the reward and they start exploring anew.

####Metric / Coordinate Processing

	"Metric / Coordinate Red"
	                     Df  Sum Sq Mean Sq F value   Pr(	F)
	spatiotemporal$GROUPS  1 0.10790  0.1079   29.94 3.38e-05 ***
	Residuals             18 0.06486  0.0036
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	"Metric / Coordinate Clear"
	                      Df Sum Sq Mean Sq F value   Pr(	F)
	spatiotemporal$GROUPS  1 0.6462  0.6462   39.38 6.44e-06 ***
	Residuals             18 0.2954  0.0164
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

![Coordinate](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/CategoricalCoordinate.pdf?raw=TRUE)

*Figure Caption: Top. Metric/Coordinate processing performance in the presence and absence of extra-maze, distal cues.*

####Topological / Categorical Processing

	"Topological / Categorical Red"
	                      Df  Sum Sq  Mean Sq F value Pr(	F)
	spatiotemporal$GROUPS  1 0.00884 0.008837   1.489  0.238
	Residuals             18 0.10685 0.005936

	##################################################################################
	"Topological / Categorical Clear"
	                     Df Sum Sq Mean Sq F value   Pr(	F)
	spatiotemporal$GROUPS  1  0.672  0.6720   78.52 5.55e-08 ***
	Residuals             18  0.154  0.0086
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

![Categorical](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/CategoricalCoordinate.pdf?raw=TRUE)

*Figure Caption: Bottom. Topological/Categorical processing performance in the presence and absence of extra-maze, distal cues.*

####Location Recognition

	"Location Recognition Red"
	                      Df Sum Sq Mean Sq F value   Pr(	F)
	spatiotemporal$GROUPS  1 0.5578  0.5578      62 3.07e-07 ***
	Residuals             18 0.1619  0.0090
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	"Location Recognition Clear"
	                     Df Sum Sq Mean Sq F value   Pr(	F)
	spatiotemporal$GROUPS  1 0.7411  0.7411   36.39 1.05e-05 ***
	Residuals             18 0.3666  0.0204
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

![Location Recognition](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/LocRec.pdf?raw=TRUE)

*Figure Caption: Spatial Location recognition performance in the presence and absence of extra-maze, distal cues.*

##Temporal

####Temporal Ordering for Visual Objects

	"TemporalOrder_Red"
	                      Df  Sum Sq  Mean Sq F value Pr(	F)
	spatiotemporal$GROUPS  1 0.02048 0.020480   2.267  0.149
	Residuals             18 0.16260 0.009033

	##################################################################################
	 "TemporalOrder_Clear"
	                      Df Sum Sq Mean Sq F value   Pr(	F)
	spatiotemporal$GROUPS  1 0.4697  0.4697   68.24 1.55e-07 ***
	Residuals             18 0.1239  0.0069
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

![Temporal Ordering](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/TempOrder.pdf?raw=TRUE)

*Figure Caption: Top. Temporal ordering for visual objects in the presence and absence of extra-maze, distal cues.*

####Temporal Order Control Task: Novelty Detection for Visual Objects

	"NoveltyDetection_Red"
	                      Df  Sum Sq Mean Sq F value Pr(	F)
	spatiotemporal$GROUPS  1 0.02592 0.02592   2.909  0.105
	Residuals             18 0.16038 0.00891

	##################################################################################
	"NoveltyDetection_Clear"
	                      Df Sum Sq Mean Sq F value   Pr(	F)
	spatiotemporal$GROUPS  1 0.8201  0.8201   82.78 3.74e-08 ***
	Residuals             18 0.1783  0.0099
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

![Novelty Detection](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/TempOrder.pdf?raw=TRUE)

*Figure Caption: Bottom. Visual object novelty detection control task in the presence and absence of extra-maze, distal cues.*

##Sensory/Perceptual

####Feature Ambiguity

	Ambiguity_Red
	                      Df Sum Sq Mean Sq F value   Pr(	F)
	spatiotemporal$GROUPS  1 0.2689 0.26889   34.13 1.56e-05 ***
	Residuals             18 0.1418 0.00788
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	Ambiguity_Clear
	                      Df Sum Sq  Mean Sq F value Pr(	F)
	spatiotemporal$GROUPS  1 0.0000 0.000005       0  0.984
	Residuals             18 0.2136 0.011865

![Feature Ambiguity](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/Ambiguous.pdf?raw=TRUE)

*Figure Caption: Top. Configural ambiguity test in the presence and absence of extra-maze, distal cues.*

####Feature Ambiguity Control Task: Novelty Detection for Configural Object


	Ambiguity_Control_Red
   	                   Df  Sum Sq Mean Sq F value Pr(>F)
	spatiotemporal$GROUPS  1 0.00018 0.00018   0.012  0.916
	Residuals             18 0.28052 0.01558

	##################################################################################
	Ambiguity_Control_Clear
	                      Df Sum Sq Mean Sq F value  Pr(>F)
	spatiotemporal$GROUPS  1 0.1186 0.11858   12.27 0.00254 **
	Residuals             18 0.1739 0.00966
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

![Feature Ambiguity](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/Ambiguous.pdf?raw=TRUE)

*Figure Caption: Bottom. Novel Configural ambiguity control test in the presence and absence of extra-maze, distal cues.*

####Object Recognition

#####Short (1 hr) Delay

	"ObjectRecognition_1hr_Red"
	                     Df  Sum Sq  Mean Sq F value Pr(	F)
	spatiotemporal$GROUPS  1 0.00924 0.009245   0.908  0.353
	Residuals             18 0.18325 0.010181

	##################################################################################
	"ObjectRecognition_1_hr_Clear"
	                      Df Sum Sq Mean Sq F value   Pr(	F)
	spatiotemporal$GROUPS  1 0.2365 0.23653   29.51 3.68e-05 ***
	Residuals             18 0.1443 0.00802

![Object Recognition](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/ObjectRec.pdf?raw=TRUE)

*Figure Caption: Top. Visual object recognition task at 1 hour delay the presence and absence of extra-maze, distal cues.*

#####Long (24 hr) Delay

	ObjectRecognition_24hr_Red
	                      Df Sum Sq Mean Sq F value   Pr(	F)
	spatiotemporal$GROUPS  1 0.2182 0.21820   31.36 2.58e-05 ***
	Residuals             18 0.1253 0.00696
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	ObjectRecognition_24hr_Clear)
	                      Df  Sum Sq Mean Sq F value   Pr(	F)
	spatiotemporal$GROUPS  1 0.25225 0.25225   46.23 2.29e-06 ***
	Residuals             18 0.09821 0.00546
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

![Object Recognition](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/ObjectRec.pdf?raw=TRUE)

*Figure Caption: Bottom. Visual object recognition task at 24 hour delay the presence and absence of extra-maze, distal cues.*

---

##Executive Function

####Spontaneous Alternation

	"DelayedAlternation"
	                      Df Sum Sq Mean Sq F value  Pr(	F)
	spatiotemporal$GROUPS  1   3125    3125   23.85 0.00012 ***
	Residuals             18   2359     131
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

![Spontaneous Alternation](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/SpontaneousAlternation.pdf?raw=TRUE)

*Figure Caption: Spontaneous/Delayed Alternation performance.*

####Response Learning

	"Response_Learning"

	Error: Within
	                                              Df Sum Sq Mean Sq F value   Pr(	F)
	response_learning$GROUP                        1   1288    1288   30.24 4.92e-07 ***
	response_learning$DAY                          1  21418   21418  502.86  < 2e-16 ***
	response_learning$GROUP:response_learning$DAY  1    333     333    7.82  0.00654 **
	Residuals                                     76   3237      43
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

![Response learning](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/ResponseAcquisition.pdf?raw=TRUE)

*Figure Caption: Response rule acquisition.*

####Reversal Learning

![Reversal Raw](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/Reversal_RAW.pdf?raw=TRUE)

*Figure Caption: Response rule reversal raw data converted to cumulative response.*

	"Reversal_Changepoint"
	                       Df Sum Sq Mean Sq F value   Pr(	F)
	response_factors$group  1   1805  1805.0   21.43 0.000208 ***
	Residuals              18   1516    84.2
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	"Reversal_Perseverative"
	                       Df Sum Sq Mean Sq F value  Pr(	F)
	response_factors$group  1  145.8  145.80   11.98 0.00278 **
	Residuals              18  219.0   12.17
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	"Reversal_Regressive"
	                       Df Sum Sq Mean Sq F value Pr(	F)
	response_factors$group  1    5.0    5.00   0.287  0.599
	Residuals              18  313.8   17.43



![Reversal Processed](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/Reversal_Factors.pdf?raw=TRUE)

*Figure Caption: Top. Changepoint, or trial at which each mouse learned to reverse the rule. Middle. Number of perseverative errors in trial 1-20 trials. Bottom. Number of Regressive erros in trials 20-40.*


---

##Motor Function (analogous to human Cerebellum Function)

####Capellini Handling

	"Capellini_Latency"
	                Df Sum Sq Mean Sq F value Pr(	F)
	capellini$GROUP  1   1201  1201.2   14.74 0.0012 **
	Residuals       18   1467    81.5
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	"Capellini_OverallAtypical"
	                Df Sum Sq Mean Sq F value  Pr(	F)
	capellini$GROUP  1  649.8   649.8   92.68 1.6e-08 ***
	Residuals       18  126.2     7.0

![Capellini latency](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/Capellini_Latency.pdf?raw=TRUE)

*Figure Caption: Top. Latency to consume capellini. Bottom. Total number of atypical behaviors.*

	"Capellini_PawsTogether"
	                Df Sum Sq Mean Sq F value   Pr(	F)
	capellini$GROUP  1  92.45   92.45   42.34 4.06e-06 ***
	Residuals       18  39.30    2.18
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	"Capellini_NoContact"
	                Df Sum Sq Mean Sq F value  Pr(	F)
	capellini$GROUP  1   45.0   45.00   20.35 0.00027 ***
	Residuals       18   39.8    2.21
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	"Capellini_MouthPull"
	                Df Sum Sq Mean Sq F value   Pr(	F)
	capellini$GROUP  1  84.05   84.05   21.46 0.000207 ***
	Residuals       18  70.50    3.92
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

![Capellini Errors](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/Capellini_Errors.pdf?raw=TRUE)

*Figure Caption: Atypical Behaviors. Top. Number of times mouse paws came together. Middle. Number of times mouse lost contact with capellini with one paw. Bottom. Number of times mouse pulled capellini with mouth rather than paw.*

####Parallel Rung Walking

	"Ladder_Raw"
	             Df Sum Sq Mean Sq F value  Pr(	F)
	ladder$groups  1   1549  1548.8   27.32 5.7e-05 ***
	Residuals     18   1020    56.7
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
	[1] " "
	[1] "Ladder_Adjusted"
	              Df   Sum Sq   Mean Sq F value  Pr(	F)
	ladder$groups  1 0.001575 0.0015753    11.7 0.00305 **
	Residuals     18 0.002423 0.0001346
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

![Parallel Rung Walking](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/ParallelRung.pdf?raw=TRUE)

*Figure Caption: Top. Raw number of foot slips in a 1 minute period of free exploration. Bottom. Number of foot slips scaled by the total number of steps.*

---

##Adaptive Function

####Nesting Behaviors

	"Nesting_Contact"
	              Df Sum Sq Mean Sq F value  Pr(	F)
	nesting$group  1   7605    7605   152.9 3.1e-10 ***
	Residuals     18    895      50
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	"Nesting_Dig"
	              Df Sum Sq Mean Sq F value   Pr(	F)
	nesting$group  1  13210   13210   318.6 6.79e-13 ***
	Residuals     18    746      41
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	"Nesting_Complete"
	              Df Sum Sq Mean Sq F value  Pr(	F)
	nesting$group  1  15125   15125    94.3 1.4e-08 ***
	Residuals     18   2887     160
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

![Nesting](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/Nesting.pdf?raw=TRUE)

*Figure Caption: Nesting Behaviors. Top. Latency to contact nesting material. Middle. Latency to first dig in nesting material. Bottom. Latency to complete nest.*

####Neophagia

	"Neophagia_NovelFood"
	                Df Sum Sq Mean Sq F value   Pr(	F)
	neophagia$group  1   3485    3485   19.59 0.000326 ***
	Residuals       18   3201     178
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	"Neophagia_NovelEnvironment"
	                Df Sum Sq Mean Sq F value   Pr(	F)
	neophagia$group  1  11424   11424   40.87 5.09e-06 ***
	Residuals       18   5032     280
	---
	Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

	##################################################################################
	"Neophagia_NovelBoth"
	                Df Sum Sq Mean Sq F value   Pr(	F)
	neophagia$group  1  31126   31126   83.74 3.44e-08 ***
	Residuals       18   6691     372

![Neophagia](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/Neophagia.pdf?raw=TRUE)

*Figure Caption: Neophagia Behaviors. Top. Latency to start to consume novel food in a familiar environemnt. Middle. Latency to start to consume familiar food in a novel environemnt. Bottom. Latency to start to consume a novel food in a novel environment.*

---

##Principal Component Analysis

![PCA Task Comparison](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/PCA_Tasks.pdf?raw=TRUE)

*Figure Caption: Principal Component Analysis focusing on behavioral paradigms. Two major components emerge, accounting for 57.76% of the variance. These components seem to be tasks dependent upon MTL structures clustering together and executive + motor + adaptive function components clustering together.*

---

![PCA Sorting](https://github.com/mrhunsaker/Ts65DnPilots/blob/master/Manuscript_Draft_Figures/Plots/PCA_Sorting.pdf?raw=TRUE)

*Figure Caption: Principal Component Analysis focusing on behavioral paradigms. Using the components extracted above, all mice were correctly sorted into groups using the primary component. The secondary component accounting for slightly over 9% of the variance failed to sort the groups effetively.*


#Discussion

###General Discussion

* Mouse ACTB tests same brain regions and cognitive domains as the ACTB designed for use in Down Syndrome subjects
* Ts65Dn mice show spatiotemporal, motor, executive, and adaptive functioning deficits
* Ts65Dn Mouse behaviorally phenocopies human subjects with Down Syndrome when given appropriate tasks
* Mouse version of ACTB can be used to more specifically assess contributions of different brain regions for intellectual disabilities observed in Down Syndrome
* Mouse ACTB may serve as a Down Syndrome-specific outcome measure for tests of novel therapeutics
* Potentially use this mouse ACTB to define prodromal states in Ts65Dn mouse for putative Alzheimer's Disease-like phenotypes or progression

###Strengths

* None of these tasks require specialized equipment or expertise (accessible to most disease researchers)
* Behavioral paradigms carefully/specifically optimized to mouse models
* Contributions of spatial & nonspatial attributes dissociated within each task
* All but 2 tasks were performed in 2 days or less (high throughput)
* No aversive components to tasks (*i.e.,* no negative reinforcement or aversive stimulus used to motivate)
* Can specifically dissect contribution of basic cognitive processes &/or brain areas to performance
* Previous work has demonstrated these tasks can be repeated for use in longitudinal studies

###Weaknesses

* We are unable to evaluate receptive vs. expressive language in mouse models
* Ts65Dn mouse model not necessarily best model for Down Syndrome genetics

###Future Directions

* Eugene Yu's 16/17/10 mouse model (best genetic mouse model of Down Syndrome)
* Single gene studies (*i.e.*, *App*, *Dyrk1*, *pep19/pcp4*, etc. triploid mice)
* Cell specific genetic models
* Ultrasonic vocalization studies for linguistic analog
* Tasks to test affective attributes of memory

#References
